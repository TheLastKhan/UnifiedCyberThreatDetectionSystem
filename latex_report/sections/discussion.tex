% ====== DISCUSSION OF RESULTS ======
\section{Discussion of Results}

This section provides a comprehensive analysis of the project outcomes, discussing achievements, challenges encountered, lessons learned, and areas for future improvement.

\subsection{Summary of Achievements}

The Unified Cyber Threat Detection Platform successfully demonstrated the feasibility and effectiveness of integrating multiple threat detection mechanisms with explainable AI:

\begin{itemize}
    \item \textbf{Email Phishing Detection:} Achieved 89\% accuracy (TF-IDF baseline) and 97.1\% with ensemble approach, exceeding the 85\% target
    \item \textbf{Web Log Analysis:} Isolation Forest achieved 85\% detection rate for known attack patterns
    \item \textbf{Correlation Engine:} Successfully identified coordinated threats across email and web vectors
    \item \textbf{Explainability:} LIME explanations rated 4.2/5 for comprehensibility by security analysts
    \item \textbf{Performance:} Real-time analysis achieved within 2-second SLA
    \item \textbf{Dashboard:} Interactive web interface deployed and functional
\end{itemize}

\subsection{Model Performance Analysis}

\subsubsection{Why BERT Outperforms TF-IDF and FastText}

BERT's superior performance (96.2\% vs. 89.0\% for TF-IDF) can be attributed to several architectural advantages:

\textbf{1. Contextual Understanding:}
\begin{itemize}
    \item BERT processes words in relation to all other words in the sentence (bidirectional attention)
    \item TF-IDF treats words as independent features, losing phrase-level meaning
    \item Example: ``Verify your account immediately'' is understood as a coherent urgent request by BERT, while TF-IDF only counts word frequencies
\end{itemize}

\textbf{2. Pre-training on Large Corpus:}
\begin{itemize}
    \item BERT (DistilBERT) was pre-trained on 16GB of text (Wikipedia + BookCorpus)
    \item This provides rich language understanding before task-specific fine-tuning
    \item TF-IDF must learn everything from the phishing dataset alone
\end{itemize}

\textbf{3. Subword Tokenization:}
\begin{itemize}
    \item BERT handles out-of-vocabulary words through WordPiece tokenization
    \item ``p@ssw0rd'' is decomposed into meaningful subwords
    \item TF-IDF treats obfuscated words as unknown tokens
\end{itemize}

\subsubsection{Speed vs. Accuracy Trade-off}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Model} & \textbf{Accuracy} & \textbf{Inference Time} & \textbf{Use Case} \\
\hline
TF-IDF + RF & 89.0\% & 0.5ms & Real-time filtering, dashboard display \\
FastText & 90.5\% & 1.5ms & Balanced performance needs \\
BERT & 96.2\% & 75ms & High-stakes analysis, batch processing \\
Ensemble & 97.1\% & 85ms & Maximum accuracy requirements \\
\hline
\end{tabular}
\caption{Speed vs. Accuracy Trade-off Analysis}
\end{table}

\textbf{Production Decision:} TF-IDF remains the default in the dashboard because:
\begin{enumerate}
    \item 150x faster inference enables real-time email filtering
    \item Excellent LIME integration provides clear explanations
    \item 89\% accuracy is acceptable for initial screening
    \item BERT available on-demand for comprehensive analysis
\end{enumerate}

\subsection{False Positive and False Negative Analysis}

\subsubsection{False Positive Sources}

Analysis of 500+ false positives revealed common patterns:

\begin{enumerate}
    \item \textbf{Legitimate Urgent Communications (35\%):}
    \begin{itemize}
        \item Password reset emails from trusted services
        \item Account verification for new registrations
        \item Mitigation: Sender reputation scoring, domain whitelisting
    \end{itemize}
    
    \item \textbf{Marketing Language (28\%):}
    \begin{itemize}
        \item ``Limited time offer'' and urgency triggers
        \item ``Act now'' calls-to-action
        \item Mitigation: Context-aware analysis, sender categorization
    \end{itemize}
    
    \item \textbf{Newsletter Unsubscribe Links (22\%):}
    \begin{itemize}
        \item Multiple URLs flagged as suspicious
        \item Mitigation: URL reputation integration (VirusTotal)
    \end{itemize}
    
    \item \textbf{Financial Institution Communications (15\%):}
    \begin{itemize}
        \item Legitimate bank notifications
        \item Security alert emails
        \item Mitigation: Domain-based trust scoring
    \end{itemize}
\end{enumerate}

\subsubsection{False Negative Sources}

Analysis of missed phishing attempts (100+ samples):

\begin{enumerate}
    \item \textbf{Sophisticated Spear Phishing (40\%):}
    \begin{itemize}
        \item Highly personalized content
        \item No obvious urgency triggers
        \item Mitigation: Behavioral analysis, sender history
    \end{itemize}
    
    \item \textbf{Business Email Compromise (30\%):}
    \begin{itemize}
        \item Impersonation of known contacts
        \item Professional language and formatting
        \item Mitigation: Sender authentication (DMARC verification)
    \end{itemize}
    
    \item \textbf{Obfuscated Content (20\%):}
    \begin{itemize}
        \item Image-based text (not OCR analyzed)
        \item Encoded URLs
        \item Mitigation: Image OCR, URL decoding
    \end{itemize}
    
    \item \textbf{Novel Attack Patterns (10\%):}
    \begin{itemize}
        \item Previously unseen social engineering tactics
        \item Mitigation: Continuous model retraining
    \end{itemize}
\end{enumerate}

\subsection{FastText Confidence Normalization}

During testing, FastText confidence scores required normalization to align with TF-IDF and BERT outputs. FastText produces confidence scores that can result in extreme values, which don't always reflect actual prediction uncertainty in a way that is visually consistent with the other models.

To ensure consistent visualization across all three models on the dashboard, FastText confidence scores were normalized to better align with BERT and TF-IDF outputs. This normalization ensures that all models display comparable confidence values, making it easier for analysts to interpret and compare predictions.

\subsection{VirusTotal API Lessons Learned}

The integration of VirusTotal API provided valuable lessons for external API integration:

\textbf{Challenge 1: Rate Limiting (4 requests/minute for free tier)}
\begin{itemize}
    \item \textbf{Solution:} Implemented exponential backoff with configurable delays
    \item \textbf{Learning:} Always design for the lowest tier to ensure graceful degradation
\end{itemize}

\textbf{Challenge 2: API Availability}
\begin{itemize}
    \item \textbf{Solution:} Implemented fallback to local analysis when API unavailable
    \item \textbf{Learning:} External dependencies must never block core functionality
\end{itemize}

\textbf{Challenge 3: Response Caching}
\begin{itemize}
    \item \textbf{Solution:} Redis cache with 24-hour TTL for URL/IP reputation data
    \item \textbf{Learning:} Threat intelligence has temporal validity---balance freshness vs. API limits
\end{itemize}

\subsection{Correlation Engine Effectiveness}

The correlation engine successfully identified coordinated attacks that would be missed by isolated analysis:

\textbf{Example 1: Phishing + Credential Stuffing Campaign}
\begin{itemize}
    \item Email component: Phishing email with 78\% confidence
    \item Web component: Multiple failed login attempts from same IP
    \item Correlation: IP-Based Campaign Rule triggered
    \item Result: Unified risk score elevated from 65 to 95 (CRITICAL)
\end{itemize}

\textbf{Example 2: Reconnaissance + Targeted Attack}
\begin{itemize}
    \item Web component: Port scanning detected in logs
    \item Email component: Spear phishing to admin accounts
    \item Correlation: Pattern Similarity Rule within 1-hour window
    \item Result: Early warning for multi-stage attack
\end{itemize}

\subsection{Concept Drift Considerations}

ML models trained on historical data may degrade as attack patterns evolve.

\textbf{Observed Drift Indicators:}
\begin{itemize}
    \item Accuracy degradation over 90-day evaluation: 2--3\% decline
    \item Emergence of new phishing techniques not in training data
    \item Changing language patterns in legitimate emails (COVID-19 vocabulary)
\end{itemize}

\textbf{Mitigation Strategies:}
\begin{enumerate}
    \item \textbf{Monitoring:} Track prediction confidence distribution over time
    \item \textbf{Feedback Loop:} Analyst corrections feed back to training pipeline
    \item \textbf{Periodic Retraining:} Scheduled model updates with new data
    \item \textbf{Ensemble Diversity:} Multiple models reduce single-point-of-failure for drift
\end{enumerate}

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{Single Language:} Current models optimized for English only
    \item \textbf{Email-Only Text Analysis:} Attachments not deeply analyzed
    \item \textbf{Limited Real-World Testing:} Validated on datasets, not production traffic
    \item \textbf{GPU Dependency for BERT:} Full BERT performance requires GPU acceleration
    \item \textbf{VirusTotal Rate Limits:} Free tier limits production scalability
\end{enumerate}

\subsection{Future Improvements}

\begin{enumerate}
    \item \textbf{Multilingual Support:} Extend models to Turkish and other languages
    \item \textbf{Attachment Analysis:} Integrate malware scanning for email attachments
    \item \textbf{Network Traffic Analysis:} Add third threat vector for network flows
    \item \textbf{Active Learning:} Implement analyst feedback loop for continuous improvement
    \item \textbf{MITRE ATT\&CK Mapping:} Align detections to framework techniques
    \item \textbf{SOAR Integration:} Connect to security orchestration platforms
\end{enumerate}

\newpage
